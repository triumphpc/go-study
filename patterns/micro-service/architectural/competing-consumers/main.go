// Паттерн "Competing Consumers" используется для распределения нагрузки между несколькими потребителями,
//которые обрабатывают сообщения или задачи из общей очереди. Этот паттерн позволяет масштабировать обработку задач,
//добавляя больше потребителей, и обеспечивает более эффективное использование ресурсов, так как каждый потребитель
//может работать независимо.
//
//Когда использовать Competing Consumers Pattern
//Высокая нагрузка: Когда система должна обрабатывать большое количество сообщений или задач, и требуется распределение нагрузки.
//Масштабируемость: Когда необходимо легко масштабировать систему, добавляя или удаляя потребителей в зависимости от нагрузки.
//Улучшение производительности: Когда требуется повысить производительность системы за счет параллельной обработки задач.
//Устойчивость к сбоям: Когда необходимо обеспечить устойчивость к сбоям, так как сбой одного потребителя не влияет на других.

//Плюсы Competing Consumers Pattern
//Масштабируемость: Легко масштабируется за счет добавления новых потребителей для обработки увеличивающегося объема задач.
//Улучшение производительности: Позволяет обрабатывать задачи параллельно, что может значительно повысить производительность.
//Устойчивость к сбоям: Сбой одного потребителя не влияет на других, что повышает надежность системы.
//Гибкость: Позволяет динамически изменять количество потребителей в зависимости от текущей нагрузки.

//Минусы Competing Consumers Pattern
//Сложность управления: Требует управления очередью и координации между потребителями.
//Потенциальные задержки: Если все потребители заняты, задачи могут оставаться в очереди дольше.
//Распределение нагрузки: Неравномерное распределение задач может привести к перегрузке некоторых потребителей.
//Сложность отладки: Параллельная обработка может усложнить отладку и мониторинг системы.

package main

import (
	"fmt"
	"math/rand"
	"sync"
	"time"
)

// Task - структура, представляющая задачу
type Task struct {
	ID int
}

// worker - функция для обработки задач
func worker(id int, tasks <-chan Task, wg *sync.WaitGroup) {
	defer wg.Done()
	for task := range tasks {
		fmt.Printf("Worker %d processing task %d\n", id, task.ID)
		time.Sleep(time.Duration(rand.Intn(1000)) * time.Millisecond) // Симулируем выполнение задачи
	}
}

func main() {
	rand.Seed(time.Now().UnixNano())

	const numWorkers = 3
	const numTasks = 10

	tasks := make(chan Task, numTasks)

	var wg sync.WaitGroup

	// Запускаем несколько рабочих горутин
	for i := 1; i <= numWorkers; i++ {
		wg.Add(1)
		go worker(i, tasks, &wg)
	}

	// Добавляем задачи в очередь
	for i := 1; i <= numTasks; i++ {
		tasks <- Task{ID: i}
	}
	close(tasks) // Закрываем канал после добавления всех задач

	// Ожидаем завершения всех задач
	wg.Wait()
}
